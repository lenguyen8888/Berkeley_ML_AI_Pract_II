{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a data perspective, our task is to develop a predictive model to identify the key determinants that influence the price of used cars. We will analyze a dataset containing features such as year, manufacturer, model, condition, cylinders, fuel, odometer, transmission, drive, size, type, paint_color, and region, and aim to understand how these variables contribute to the price of the vehicles. Our goal is to leverage statistical and machine learning techniques to uncover relationships and patterns within the data that can inform our pricing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to Get Familiar with the Dataset and Identify Quality Issues\n",
    "\n",
    "1. **Load the Data**\n",
    "    - Import the dataset into a data manipulation tool such as Python (using pandas) or R.\n",
    "    - Display the first few rows to get an initial sense of the data structure.\n",
    "\n",
    "2. **Data Overview**\n",
    "    - Check the dimensions of the dataset (number of rows and columns).\n",
    "    - Review column names and data types to ensure they align with the expected features.\n",
    "\n",
    "3. **Handle Missing Values**\n",
    "    - Identify columns with missing values and the proportion of missing data in each column.\n",
    "\n",
    "4. **Descriptive Statistics**\n",
    "    - Calculate summary statistics (mean, median, mode, standard deviation) for numerical columns to understand the distribution of the data.\n",
    "    - For categorical columns, count the occurrences of each category.\n",
    "\n",
    "5. **Data Cleaning**\n",
    "    - Remove or impute any rows with significant amounts of missing data or outliers.\n",
    "    - Standardize the formats of any categorical columns (e.g., ensure all `manufacturer` names are consistently formatted).\n",
    "\n",
    "6. **Identify Duplicates**\n",
    "    - Check for and remove any duplicate rows that may skew analysis.\n",
    "\n",
    "7. **Data Transformation**\n",
    "    - Convert categorical variables into numerical formats if necessary (e.g., using one-hot encoding).\n",
    "    - Normalize or scale numerical variables to ensure they are on a comparable scale for modeling.\n",
    "\n",
    "8. **Exploratory Data Analysis (EDA)**\n",
    "    - Create visualizations such as histograms, box plots, and scatter plots to identify trends, patterns, and outliers in the data.\n",
    "    - Analyze correlations between variables to identify potential drivers of the target variable (`price`).\n",
    "\n",
    "9. **Feature Engineering**\n",
    "    - Create new features that may be relevant, such as `car_age` (derived from `year`).\n",
    "    - Consider aggregating or combining features that might have a joint impact on the target variable.\n",
    "\n",
    "10. **Data Quality Check**\n",
    "    - Validate data consistency, ensuring no discrepancies or logical errors within the columns.\n",
    "    - Document any data quality issues and the steps taken to address them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/vehicles.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                  region  price  year manufacturer model  \\\n",
      "0  7222695916                prescott   6000   NaN          NaN   NaN   \n",
      "1  7218891961            fayetteville  11900   NaN          NaN   NaN   \n",
      "2  7221797935            florida keys  21000   NaN          NaN   NaN   \n",
      "3  7222270760  worcester / central MA   1500   NaN          NaN   NaN   \n",
      "4  7210384030              greensboro   4900   NaN          NaN   NaN   \n",
      "\n",
      "  condition cylinders fuel  odometer title_status transmission  VIN drive  \\\n",
      "0       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
      "1       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
      "2       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
      "3       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
      "4       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
      "\n",
      "  size type paint_color state  \n",
      "0  NaN  NaN         NaN    az  \n",
      "1  NaN  NaN         NaN    ar  \n",
      "2  NaN  NaN         NaN    fl  \n",
      "3  NaN  NaN         NaN    ma  \n",
      "4  NaN  NaN         NaN    nc  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            426880 non-null  int64  \n",
      " 1   region        426880 non-null  object \n",
      " 2   price         426880 non-null  int64  \n",
      " 3   year          425675 non-null  float64\n",
      " 4   manufacturer  409234 non-null  object \n",
      " 5   model         421603 non-null  object \n",
      " 6   condition     252776 non-null  object \n",
      " 7   cylinders     249202 non-null  object \n",
      " 8   fuel          423867 non-null  object \n",
      " 9   odometer      422480 non-null  float64\n",
      " 10  title_status  418638 non-null  object \n",
      " 11  transmission  424324 non-null  object \n",
      " 12  VIN           265838 non-null  object \n",
      " 13  drive         296313 non-null  object \n",
      " 14  size          120519 non-null  object \n",
      " 15  type          334022 non-null  object \n",
      " 16  paint_color   296677 non-null  object \n",
      " 17  state         426880 non-null  object \n",
      "dtypes: float64(2), int64(2), object(14)\n",
      "memory usage: 58.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   region        426880 non-null  object \n",
      " 1   price         426880 non-null  int64  \n",
      " 2   year          425675 non-null  float64\n",
      " 3   manufacturer  409234 non-null  object \n",
      " 4   model         421603 non-null  object \n",
      " 5   odometer      422480 non-null  float64\n",
      " 6   title_status  418638 non-null  object \n",
      " 7   transmission  424324 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 26.1+ MB\n",
      "before dropna None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 391154 entries, 27 to 426879\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   region        391154 non-null  object \n",
      " 1   price         391154 non-null  int64  \n",
      " 2   year          391154 non-null  float64\n",
      " 3   manufacturer  391154 non-null  object \n",
      " 4   model         391154 non-null  object \n",
      " 5   odometer      391154 non-null  float64\n",
      " 6   title_status  391154 non-null  object \n",
      " 7   transmission  391154 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 26.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# drop columns id, state since region is already in the data\n",
    "df.drop(columns=['id', 'state'], inplace=True)\n",
    "# drop columns with too few Non-Null count < 400000\n",
    "df.drop(columns=['condition', 'cylinders', 'fuel', 'VIN',\\\n",
    "                  'drive', 'size', 'type', 'paint_color', \\\n",
    "                    ], inplace=True)\n",
    "print('before dropna', df.info())\n",
    "# drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'car_age' feature\n",
    "df['car_age'] = 2025 - df['year']\n",
    "df.drop(columns=['year'], inplace=True)\n",
    "\n",
    "# drop 'manufacturer', 'model', 'region' since the fields explode the number of features\n",
    "df.drop(columns=['manufacturer', 'model', 'region'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns\n",
    "num_features = ['odometer', 'car_age']\n",
    "cat_features = ['title_status', 'transmission']\n",
    "\n",
    "# Create transformers for numerical and categorical data\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable and features\n",
    "X = df.drop(columns=['price'])\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_reg = Ridge()\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_reg = Lasso(max_iter=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 8927603.415376697\n",
      "Ridge Regression RMSE: 8927602.025768345\n",
      "Lasso Regression RMSE: 8927600.967181185\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation for Linear Regression\n",
    "linear_scores = cross_val_score(linear_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "linear_rmse_scores = np.sqrt(-linear_scores)\n",
    "print(\"Linear Regression RMSE:\", linear_rmse_scores.mean())\n",
    "\n",
    "# Perform cross-validation for Ridge Regression\n",
    "ridge_scores = cross_val_score(ridge_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_rmse_scores = np.sqrt(-ridge_scores)\n",
    "print(\"Ridge Regression RMSE:\", ridge_rmse_scores.mean())\n",
    "\n",
    "# Perform cross-validation for Lasso Regression\n",
    "lasso_scores = cross_val_score(lasso_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_rmse_scores = np.sqrt(-lasso_scores)\n",
    "print(\"Lasso Regression RMSE:\", lasso_rmse_scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Parameters: {'alpha': 100}\n",
      "Best Ridge RMSE: 12582417.941447372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ngle\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.109e+16, tolerance: 4.954e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ngle\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+16, tolerance: 2.035e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ngle\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.089e+16, tolerance: 4.954e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ngle\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.906e+16, tolerance: 4.752e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ngle\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.109e+16, tolerance: 4.954e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ngle\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.089e+16, tolerance: 4.954e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\ngle\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.906e+16, tolerance: 4.752e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso Parameters: {'alpha': 100}\n",
      "Best Lasso RMSE: 12582416.870036736\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression hyperparameter tuning\n",
    "ridge_param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "ridge_grid_search = GridSearchCV(ridge_reg, ridge_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Ridge Parameters:\", ridge_grid_search.best_params_)\n",
    "print(\"Best Ridge RMSE:\", np.sqrt(-ridge_grid_search.best_score_))\n",
    "\n",
    "# Lasso Regression hyperparameter tuning\n",
    "lasso_param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "lasso_grid_search = GridSearchCV(lasso_reg, lasso_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "print(\"Best Lasso Parameters:\", lasso_grid_search.best_params_)\n",
    "print(\"Best Lasso RMSE:\", np.sqrt(-lasso_grid_search.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test RMSE: 4415627.742608839\n",
      "Ridge Regression Test RMSE: 4415624.004995548\n",
      "Lasso Regression Test RMSE: 4415612.524867608\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation for Linear Regression\n",
    "linear_reg.fit(X_train, y_train)\n",
    "linear_predictions = linear_reg.predict(X_test)\n",
    "print(\"Linear Regression Test RMSE:\", np.sqrt(mean_squared_error(y_test, linear_predictions)))\n",
    "\n",
    "# Final evaluation for Ridge Regression\n",
    "best_ridge_reg = ridge_grid_search.best_estimator_\n",
    "best_ridge_reg.fit(X_train, y_train)\n",
    "ridge_predictions = best_ridge_reg.predict(X_test)\n",
    "print(\"Ridge Regression Test RMSE:\", np.sqrt(mean_squared_error(y_test, ridge_predictions)))\n",
    "\n",
    "\n",
    "# Final evaluation for Lasso Regression\n",
    "best_lasso_reg = lasso_grid_search.best_estimator_\n",
    "best_lasso_reg.fit(X_train, y_train)\n",
    "lasso_predictions = best_lasso_reg.predict(X_test)\n",
    "print(\"Lasso Regression Test RMSE:\", np.sqrt(mean_squared_error(y_test, lasso_predictions)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature    Coefficient  Absolute Coefficient\n",
      "4      title_status_missing -179566.411821         179566.411821\n",
      "2        title_status_clean  107486.587606         107486.587606\n",
      "5   title_status_parts only  -84330.884858          84330.884858\n",
      "1                   car_age   70768.131592          70768.131592\n",
      "3         title_status_lien   68395.037624          68395.037624\n",
      "6      title_status_rebuilt   55994.518594          55994.518594\n",
      "9       transmission_manual  -32297.917393          32297.917393\n",
      "7      title_status_salvage   32021.152854          32021.152854\n",
      "8    transmission_automatic   20657.255977          20657.255977\n",
      "10       transmission_other   11640.661416          11640.661416\n",
      "0                  odometer   -1309.312200           1309.312200\n"
     ]
    }
   ],
   "source": [
    "# Assuming linear_reg or ridge_reg is the trained model\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = preprocessor.transformers_[0][2] + list(preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(cat_features))\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = linear_reg.coef_\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "importance_df['Absolute Coefficient'] = importance_df['Coefficient'].abs()\n",
    "importance_df = importance_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature    Coefficient  Absolute Coefficient\n",
      "4      title_status_missing -156186.221529         156186.221529\n",
      "2        title_status_clean   94976.899144          94976.899144\n",
      "1                   car_age   70521.429273          70521.429273\n",
      "5   title_status_parts only  -51331.261367          51331.261367\n",
      "3         title_status_lien   50938.508161          50938.508161\n",
      "6      title_status_rebuilt   42688.374998          42688.374998\n",
      "9       transmission_manual  -32103.708217          32103.708217\n",
      "8    transmission_automatic   20655.083360          20655.083360\n",
      "7      title_status_salvage   18913.700593          18913.700593\n",
      "10       transmission_other   11448.624865          11448.624865\n",
      "0                  odometer   -1334.705733           1334.705733\n"
     ]
    }
   ],
   "source": [
    "# Get feature names after preprocessing\n",
    "feature_names = preprocessor.transformers_[0][2] + list(preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(cat_features))\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = best_ridge_reg.coef_\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "importance_df['Absolute Coefficient'] = importance_df['Coefficient'].abs()\n",
    "importance_df = importance_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Feature    Coefficient  Absolute Coefficient\n",
      "4    title_status_missing -158145.345059         158145.345059\n",
      "1                 car_age   70041.587345          70041.587345\n",
      "2      title_status_clean   56687.191414          56687.191414\n",
      "9     transmission_manual  -41458.516723          41458.516723\n",
      "8  transmission_automatic    9346.046231           9346.046231\n",
      "7    title_status_salvage   -7948.103417           7948.103417\n",
      "0                odometer   -1270.613516           1270.613516\n"
     ]
    }
   ],
   "source": [
    "# Assuming lasso_reg is the trained model\n",
    "coefficients = best_lasso_reg.coef_\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "importance_df = importance_df[importance_df['Coefficient'] != 0]\n",
    "importance_df['Absolute Coefficient'] = importance_df['Coefficient'].abs()\n",
    "importance_df = importance_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Inventory Analysis Report\n",
    "\n",
    "## Introduction\n",
    "This report presents the findings from our analysis of various features affecting vehicle pricing. We performed Linear Regression, Ridge Regression, and Lasso Regression to identify key features and their impact on pricing. The main audience for this report includes used car dealers looking to optimize their inventory based on data-driven insights.\n",
    "\n",
    "## Features Analyzed\n",
    "We analyzed the following features:\n",
    "- **Numerical Features:** `odometer`, `car_age`\n",
    "- **Categorical Features:** `title_status`, `transmission`\n",
    "\n",
    "## Ridge Regression Findings\n",
    "The Ridge Regression model provided the following insights:\n",
    "\n",
    "| Feature                  | Coefficient        | Absolute Coefficient |\n",
    "|--------------------------|-------------------:|---------------------:|\n",
    "| title_status_missing     | -156186.221529     | 156186.221529        |\n",
    "| title_status_clean       | 94976.899144       | 94976.899144         |\n",
    "| car_age                  | 70521.429273       | 70521.429273         |\n",
    "| title_status_parts only  | -51331.261367      | 51331.261367         |\n",
    "| title_status_lien        | 50938.508161       | 50938.508161         |\n",
    "| title_status_rebuilt     | 42688.374998       | 42688.374998         |\n",
    "| transmission_manual      | -32103.708217      | 32103.708217         |\n",
    "| transmission_automatic   | 20655.083360       | 20655.083360         |\n",
    "| title_status_salvage     | 18913.700593       | 18913.700593         |\n",
    "| transmission_other       | 11448.624865       | 11448.624865         |\n",
    "| odometer                 | -1334.705733       | 1334.705733          |\n",
    "\n",
    "### Interpretation\n",
    "- Vehicles with a `missing` title status significantly reduce the price.\n",
    "- A `clean` title status positively impacts the price.\n",
    "- `Car age` also has a positive effect on the price.\n",
    "- `Manual transmission` has a negative effect on the price compared to `automatic transmission`.\n",
    "\n",
    "## Lasso Regression Findings\n",
    "The Lasso Regression model provided the following insights:\n",
    "\n",
    "| Feature                  | Coefficient        | Absolute Coefficient |\n",
    "|--------------------------|-------------------:|---------------------:|\n",
    "| title_status_missing     | -158145.345059     | 158145.345059        |\n",
    "| car_age                  | 70041.587345       | 70041.587345         |\n",
    "| title_status_clean       | 56687.191414       | 56687.191414         |\n",
    "| transmission_manual      | -41458.516723      | 41458.516723         |\n",
    "| transmission_automatic   | 9346.046231        | 9346.046231          |\n",
    "| title_status_salvage     | -7948.103417       | 7948.103417          |\n",
    "| odometer                 | -1270.613516       | 1270.613516          |\n",
    "\n",
    "### Interpretation\n",
    "- Similar to Ridge Regression, a `missing` title status significantly reduces the price.\n",
    "- `Car age` positively impacts the price, though with slightly different magnitude compared to Ridge.\n",
    "- Lasso Regression emphasizes fewer features but shows similar patterns in `transmission` effects.\n",
    "\n",
    "## Conclusion\n",
    "Both Ridge and Lasso Regression models highlight the significant impact of `title status`, `car age`, and `transmission` type on vehicle pricing. Dealers can use these insights to fine-tune their inventory strategies, focusing on vehicles with clean titles, newer age, and automatic transmissions to maximize their profit potential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
